# app_no_faiss.py
import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search, get_model
import torch
import numpy as np
import time
import psutil
import os

st.set_page_config(page_title="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑ –§–õ", layout="centered")
st.title("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑")

@st.cache_data
def get_data():
    df = load_all_excels()
    # –∑–∞—Ä–∞–Ω–µ–µ —Å—á–∏—Ç–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è –≤—Å–µ–≥–æ df
    model = get_model()
    phrase_embs_tensor = model.encode(df["phrase_proc"].tolist(), convert_to_tensor=True)
    df.attrs["phrase_embs"] = phrase_embs_tensor
    return df

df = get_data()

# üîò –í—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏
all_topics = sorted({topic for topics in df['topics'] for topic in topics})
selected_topics = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–∏—Å–∫–∞):", all_topics)
filter_search_by_topics = st.checkbox("–ò—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ç–∏–∫–∞—Ö", value=False)

def get_resource_usage():
    process = psutil.Process(os.getpid())
    mem_mb = process.memory_info().rss / 1024 ** 2
    cpu_percent = psutil.cpu_percent(interval=None)
    return mem_mb, cpu_percent

# üì• –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:")
if query:
    try:
        # üîπ –∑–∞–º–µ—Ä –¥–æ –ø–æ–∏—Å–∫–∞
        start_time = time.time()
        mem_before, cpu_before = get_resource_usage()

        search_df = df
        if filter_search_by_topics and selected_topics:
            mask = df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))
            search_df = df[mask].copy()

        if search_df.empty:
            st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º.")
        else:
            results = semantic_search(query, search_df)
            exact_results = keyword_search(query, search_df)

        # üîπ –∑–∞–º–µ—Ä –ø–æ—Å–ª–µ –ø–æ–∏—Å–∫–∞
        end_time = time.time()
        mem_after, cpu_after = get_resource_usage()

        # üìä –º–µ—Ç—Ä–∏–∫–∏
        st.markdown(f"""
        ### üìä –ú–µ—Ç—Ä–∏–∫–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è:
        - ‚è±Ô∏è –í—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞: **{end_time - start_time:.3f} —Å–µ–∫**
        - üíæ RAM –¥–æ: **{mem_before:.1f} MB**
        - üíæ RAM –ø–æ—Å–ª–µ: **{mem_after:.1f} MB**
        - üßÆ CPU: **{cpu_after:.1f}%**
        """)

        # üîç –≤—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if results:
            st.markdown("### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
            for score, phrase_full, topics, comment in results:
                with st.container():
                    st.write(f"üß† {phrase_full} | –¢–µ–º–∞—Ç–∏–∫–∏: {', '.join(topics)} | üéØ {score:.2f}")
                    if comment and str(comment).strip().lower() != "nan":
                        st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π").markdown(comment)
        else:
            st.warning("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —É–º–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

        if exact_results:
            st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫:")
            for phrase, topics, comment in exact_results:
                with st.container():
                    st.write(f"üìå {phrase} | –¢–µ–º–∞—Ç–∏–∫–∏: {', '.join(topics)}")
                    if comment and str(comment).strip().lower() != "nan":
                        st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π").markdown(comment)
        else:
            st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–æ—á–Ω–æ–º –ø–æ–∏—Å–∫–µ.")
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")
