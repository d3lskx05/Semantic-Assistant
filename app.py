import streamlit as st
from utils import load_all_excels, semantic_search, keyword_search, get_model
import torch  # –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ç–µ–Ω–∑–æ—Ä–∞–º–∏

st.set_page_config(page_title="–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑ –§–õ", layout="centered")
st.title("ü§ñ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ—Ä–∞–∑")

@st.cache_data
def get_data():
    df = load_all_excels()
    model = get_model()
    df.attrs['phrase_embs'] = model.encode(df['phrase_proc'].tolist(), convert_to_tensor=True)
    return df

df = get_data()

# üîò –í—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏
all_topics = sorted({topic for topics in df['topics'] for topic in topics})

# --- –í–∫–ª–∞–¥–∫–∏ ---
tab1, tab2, tab3 = st.tabs(["üîç –ü–æ–∏—Å–∫", "üö´ –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º", "‚úÖ/‚ùå –î–∞ –∏ –ù–µ—Ç"])

# ============= TAB 1: –ü–û–ò–°–ö =============
with tab1:
    selected_topics = st.multiselect("–§–∏–ª—å—Ç—Ä –ø–æ —Ç–µ–º–∞—Ç–∏–∫–∞–º (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –ø–æ–∏—Å–∫–∞):", all_topics)
    filter_search_by_topics = st.checkbox("–ò—Å–∫–∞—Ç—å —Ç–æ–ª—å–∫–æ –≤ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–µ–º–∞—Ç–∏–∫–∞—Ö", value=False)

    # üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º
    if selected_topics:
        st.markdown("### üìÇ –§—Ä–∞–∑—ã –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º:")
        filtered_df = df[df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))]
        for row in filtered_df.itertuples():
            with st.container():
                st.markdown(
                    f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                        <div style="font-size: 18px; font-weight: 600; color: #333;">üìù {row.phrase_full}</div>
                        <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(row.topics)}</strong></div>
                    </div>""",
                    unsafe_allow_html=True
                )
                if row.comment and str(row.comment).strip().lower() != "nan":
                    with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                        st.markdown(row.comment)

    # üì• –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
    query = st.text_input("–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å:")

    if query:
        try:
            search_df = df
            if filter_search_by_topics and selected_topics:
                mask = df['topics'].apply(lambda topics: any(t in selected_topics for t in topics))
                search_df = df[mask]

                # –°–æ–≥–ª–∞—Å—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º DF
                full_embs = df.attrs.get('phrase_embs', None)
                if full_embs is not None:
                    indices = search_df.index.tolist()
                    if isinstance(full_embs, torch.Tensor):
                        if indices:
                            search_df.attrs['phrase_embs'] = full_embs[indices]
                        else:
                            search_df.attrs['phrase_embs'] = full_embs.new_empty((0, full_embs.size(1)))
                    else:
                        import numpy as np
                        arr = np.asarray(full_embs)
                        search_df.attrs['phrase_embs'] = arr[indices]

            if search_df.empty:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —Ç–µ–º–∞—Ç–∏–∫–∞–º.")
            else:
                results = semantic_search(query, search_df)
                if results:
                    st.markdown("### üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —É–º–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞:")
                    for score, phrase_full, topics, comment in results:
                        with st.container():
                            st.markdown(
                                f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                    <div style="font-size: 18px; font-weight: 600; color: #333;">üß† {phrase_full}</div>
                                    <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                                    <div style="margin-top: 2px; font-size: 13px; color: #999;">üéØ –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score:.2f}</div>
                                </div>""",
                                unsafe_allow_html=True
                            )
                            if comment and str(comment).strip().lower() != "nan":
                                with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                    st.markdown(comment)
                else:
                    st.warning("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —É–º–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

                exact_results = keyword_search(query, search_df)
                if exact_results:
                    st.markdown("### üß∑ –¢–æ—á–Ω—ã–π –ø–æ–∏—Å–∫:")
                    for phrase, topics, comment in exact_results:
                        with st.container():
                            st.markdown(
                                f"""<div style="border: 1px solid #e0e0e0; border-radius: 12px; padding: 16px; margin-bottom: 12px; background-color: #f9f9f9; box-shadow: 0 2px 6px rgba(0,0,0,0.05);">
                                    <div style="font-size: 18px; font-weight: 600; color: #333;">üìå {phrase}</div>
                                    <div style="margin-top: 4px; font-size: 14px; color: #666;">üîñ –¢–µ–º–∞—Ç–∏–∫–∏: <strong>{', '.join(topics)}</strong></div>
                                </div>""",
                                unsafe_allow_html=True
                            )
                            if comment and str(comment).strip().lower() != "nan":
                                with st.expander("üí¨ –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π", expanded=False):
                                    st.markdown(comment)
                else:
                    st.info("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ —Ç–æ—á–Ω–æ–º –ø–æ–∏—Å–∫–µ.")

        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {e}")


# ============= TAB 2: –ù–ï –ò–°–ü–û–õ–¨–ó–£–ï–ú =============
with tab2:
    st.markdown("### üö´ –¢–µ–º–∞—Ç–∏–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ **–Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º**")
    unused_topics = [
        "–ü—Ä–∏–º–µ—Ä —Ç–µ–º–∞—Ç–∏–∫–∏ 1",
        "–ü—Ä–∏–º–µ—Ä —Ç–µ–º–∞—Ç–∏–∫–∏ 2",
        "–ü—Ä–∏–º–µ—Ä —Ç–µ–º–∞—Ç–∏–∫–∏ 3"
    ]
    for topic in unused_topics:
        st.markdown(f"- {topic}")


# ============= TAB 3: –î–ê/–ù–ï–¢ =============
def render_phrases_grid(phrases, cols=3, color="#e0f7fa"):
    rows = [phrases[i:i+cols] for i in range(0, len(phrases), cols)]
    for row in rows:
        cols_streamlit = st.columns(cols)
        for col, phrase in zip(cols_streamlit, row):
            col.markdown(
                f"""<div style="background-color:{color};
                                padding:6px 10px;
                                border-radius:12px;
                                display:inline-block;
                                margin:4px;
                                font-size:14px;">{phrase}</div>""",
                unsafe_allow_html=True
            )

with tab3:
    st.markdown("### ‚úÖ –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ '–î–ê'")
    yes_phrases = [
        "–ü–æ–¥—Å–∫–∞–∑–∞—Ç—å", "–ü–æ–º–Ω—é", "–•–æ—Ä–æ—à–æ", "–î–∞", "–ê–≥–∞", "–£–≥—É",
        "–î–∞ –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É", "–û—Å—Ç–∞–ª–∏—Å—å", "–ú–æ–∂–Ω–æ", "–ñ–≥–∏", "–í–∞–ª—è–π", "–ì–æ—Ç–æ–≤",
        "–ù—É-–Ω—É", "–ë—ã—Å—Ç—Ä–µ–µ", "–ü—Ä–æ–≤–µ—Ä—å", "–ü—Ä–æ–≤–µ—Ä—è–π", "–í—Å–µ —Ä–∞–≤–Ω–æ —Ö–æ—á—É",
        "–ü–æ–¥—Å–∫–∞–∂–∏—Ç–µ", "–†–∞—Å—Å–∫–∞–∂–∏", "–°–∫–∞–∂–∏", "–ü—Ä–æ–≤–µ—Ä–∏–ª", "–î–∞–≤–∞–ª",
        "–Ø –º–æ–≥—É", "–£ –º–µ–Ω—è –≤–æ–ø—Ä–æ—Å –µ—Å—Ç—å", "–°–∫–∞–∑–∞–ª", "–ü—Ä–æ–∫–æ–Ω—Å—É–ª—å—Ç–∏—Ä—É–π—Ç–µ", "–ü—Ä–æ–±–æ–≤–∞–ª–∞"
    ]
    render_phrases_grid(yes_phrases, cols=3, color="#d1f5d3")

    st.markdown("---")

    st.markdown("### ‚ùå –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏ '–ù–ï–¢'")
    no_phrases = [
        "–ù–µ –Ω–∞–¥–æ", "–ù–µ —Ö–æ—á—É", "–ù–µ –≥–æ—Ç–æ–≤", "–ù–µ –ø–æ–º–Ω—é", "–ù–µ –ø—Ä–æ–±–æ–≤–∞–ª–∞"
    ]
    render_phrases_grid(no_phrases, cols=3, color="#f9d6d5")
